{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28",
      "mount_file_id": "1g1czWlZ1DKcFy8tFmF3UJt0f0Wv_bvbU",
      "authorship_tag": "ABX9TyMl8NiV/0eG/vmfLlbNMK4F"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Knowledge Based System by Gemini LLM"
      ],
      "metadata": {
        "id": "rSz_jOvBnEBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Necessary Libraries"
      ],
      "metadata": {
        "id": "wHTg9TLtmQUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import getpass\n",
        "import requests\n",
        "from IPython.display import Image\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings, HuggingFaceEmbeddings # Import HuggingFaceEmbeddings here\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from huggingface_hub import login\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.vectorstores import Chroma\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from langchain.chains import LLMChain\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSZ8leBZIVNQ",
        "outputId": "4cf8ec11-023c-4256-9dff-9e3dec86a4d0"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up API Keys"
      ],
      "metadata": {
        "id": "IEwJzf7amhLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Project/Chat_with_PDF/env.txt\", \"r\") as file:\n",
        "    # Read the line and extract the key part\n",
        "    line = file.read().strip()\n",
        "    # Use string splitting to extract the value between the quotes\n",
        "    GOOGLE_API_KEY = line.split('=')[1].strip().strip('\"')\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Provide your Google API Key\")"
      ],
      "metadata": {
        "id": "Spfh2sxjj415"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating poem by LLM"
      ],
      "metadata": {
        "id": "83pZBYYAmuvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "result = llm.invoke(\"Write a poem about Bangladesh\")\n",
        "print(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Obi4S83XInE4",
        "outputId": "6f4f744f-ec3a-4e08-c2a4-88eb5e62dc8a"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A land of emerald rice fields, where rivers flow,\n",
            "The Ganges, Brahmaputra, a watery show.\n",
            "Bangladesh, a tapestry of green and blue,\n",
            "Where life unfolds, vibrant and new.\n",
            "\n",
            "The Sundarbans, a mangrove maze,\n",
            "Home to tigers, a wild, watery haze.\n",
            "The Bay of Bengal, a vast, restless sea,\n",
            "Where fishermen sail, with stories to be.\n",
            "\n",
            "From Dhaka's bustling streets, to Chittagong's port,\n",
            "History whispers, in every fort.\n",
            "The Liberation War, a fight for freedom's call,\n",
            "A nation reborn, standing tall.\n",
            "\n",
            "The spirit of resilience, in every heart,\n",
            "A tapestry of cultures, a work of art.\n",
            "With laughter and song, they celebrate life,\n",
            "In this land of beauty, despite the strife.\n",
            "\n",
            "The call to prayer, a gentle chime,\n",
            "Echoes across the land, transcending time.\n",
            "Bangladesh, a land of hope and grace,\n",
            "A vibrant soul, in this sacred space. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### German Translator"
      ],
      "metadata": {
        "id": "HC8VBmEQmzt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_template = \"Translate the following from English into {language}\"\n",
        "query = \"\"\"\n",
        "\n",
        "        How are you? What do you know about Berlin?\n",
        "\n",
        " \"\"\"\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", query)]\n",
        ")\n",
        "\n",
        "chain = prompt_template | llm\n",
        "response = chain.invoke({\"language\": \"Germany\"})\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l02QU0-pSNbp",
        "outputId": "7099a6c1-e790-44e1-f023-a01616606b59"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wie geht es dir? Was weißt du über Berlin? \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question Answer query from Multiple PDF"
      ],
      "metadata": {
        "id": "xkA9mC1xm6oD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pdf_text(folder_path):\n",
        "    text = \"\"\n",
        "\n",
        "    # Search for all PDF files in the specified folder\n",
        "    pdf_docs = [file for file in os.listdir(folder_path) if file.endswith('.pdf')]\n",
        "\n",
        "    for pdf in pdf_docs:\n",
        "        # Construct the full path to each PDF file\n",
        "        pdf_path = os.path.join(folder_path, pdf)\n",
        "        pdf_reader = PdfReader(pdf_path)\n",
        "\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def get_text_chunks(text):\n",
        "  text_splitter = CharacterTextSplitter(\n",
        "      separator=\"\\n\",\n",
        "      chunk_size=1000,\n",
        "      chunk_overlap=200,\n",
        "      length_function=len\n",
        "  )\n",
        "  chunks = text_splitter.split_text(text)\n",
        "  return chunks"
      ],
      "metadata": {
        "id": "g4lSm4SBYy87"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Project/Chat_with_PDF/Data\"\n",
        "\n",
        "text = get_pdf_text(pdf_path)\n",
        "chunks = get_text_chunks(text)\n",
        "\n",
        "system_template = \"\"\"\n",
        "\n",
        "          ### EXTRACTED TEXT FROM PDF\n",
        "          {extracted_data}\n",
        "\n",
        "          ### INSTRUCTIONS\n",
        "          You are a Knowledgebased Agent. Your job is to response user query from the PDF which is stored in {extracted_data}.\n",
        "          User will ask any questions reagrding the content in the PDF. You have to answer them apropriately.\n",
        "\n",
        "          ### ONLY VALID ANSWER\n",
        "          ### IF NOT IN THE PDF, JUST REPLY NOT IN THE PDF\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "\n",
        "query = \"\"\"\n",
        "    How many person in the pdf?\n",
        " \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", query)]\n",
        ")\n",
        "\n",
        "chain = prompt_template | llm\n",
        "response = chain.invoke({\"extracted_data\": chunks})\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_A35M6xc9a9",
        "outputId": "b5e55fad-4675-4682-de53-9a41f08d1596"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 6 people mentioned in the PDF. \n",
            "\n"
          ]
        }
      ]
    }
  ]
}