{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nafis/anaconda3/envs/llm_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import textwrap\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Load the GROQ API key\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"Llama3-8b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a document assistant that helps users to find information in a context.\n",
    "    Please provide the most accurate response based on the context and inputs\n",
    "    only give information that is in the context not in general\n",
    "    <context>\n",
    "    {context}\n",
    "    <context>\n",
    "    Questions:{input}\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store DB is ready\n"
     ]
    }
   ],
   "source": [
    "def vector_embedding(uploaded_file_path):\n",
    "    if \"vectors\" not in globals():\n",
    "        # Load and process the PDF file\n",
    "        embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "        loader = PyPDFLoader(uploaded_file_path)  # Load the PDF file\n",
    "        docs = loader.load()  # Document Loading\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)  # Chunk Creation\n",
    "        final_documents = text_splitter.split_documents(docs[:20])  # Splitting\n",
    "        vectors = FAISS.from_documents(final_documents, embeddings)  # Vector embeddings\n",
    "        return vectors, final_documents\n",
    "    else:\n",
    "        print(\"Document already embedded.\")\n",
    "        return vectors, final_documents\n",
    "\n",
    "# Get the path of the PDF file from user\n",
    "uploaded_file_path = \"../Data/sample.pdf\"\n",
    "# Process the file to create the vector embeddings\n",
    "vectors, final_documents = vector_embedding(uploaded_file_path)\n",
    "print(\"Vector Store DB is ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response time: 0.06782583899999972\n",
      "Based on the provided context, it appears that this is a sample PDF file\n",
      "containing a block of text in a decorative font. The text does not seem to have\n",
      "any specific topic or theme, but rather appears to be a collection of Latin\n",
      "phrases and sentences that are not grammatically correct.  It is difficult to\n",
      "determine what this text is about without more context or information. If you\n",
      "could provide more context or clarify what you are looking for, I may be able to\n",
      "provide a more accurate answer.\n"
     ]
    }
   ],
   "source": [
    "# Ask the user to enter their question\n",
    "prompt1 = \"what is this about?\"\n",
    "\n",
    "if prompt1:\n",
    "    document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    retriever = vectors.as_retriever()\n",
    "    retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "    start = time.process_time()\n",
    "    response = retrieval_chain.invoke({'input': prompt1})\n",
    "    print(f\"Response time: {time.process_time() - start}\")\n",
    "    # print(f\"Answer: {response['answer']}\")\n",
    "    wrapped_text = textwrap.fill(response['answer'], width=80)\n",
    "    print(wrapped_text)\n",
    "else:\n",
    "    print(\"Please enter a valid question.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
